import os
import requests

import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions
from openai import OpenAI


chroma_client = chromadb.PersistentClient(
    path='./db',
    settings=Settings(),
)

embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name="intfloat/multilingual-e5-large"
)


class Agent:
    def __init__(self,):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.messages = []
        self.end = False

    def chat_completion(self, model='gpt-4o-mini', max_tokens=256, temperature=1.):
        response = self.client.chat.completions.create(
            messages=self.messages, 
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            )
        assistant_message = response.choices[0].message.content
        return assistant_message


class WeatherAgent(Agent):
    def __init__(self, ):
        super().__init__()
        self.weather_api_key = os.getenv("WEATHER_API_KEY")
        self.messages = [{"role": "system", "content": self.initialize_system_message()}]
    
    @staticmethod
    def initialize_system_message():
        return """ë‹¹ì‹ ì€ íŒ¨ìŠ¤íŠ¸íˆ¬ì–´ ì—¬í–‰ì‚¬ì˜ ë‚ ì”¨ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” AI Assistantì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ Message Historyì™€ Weather Infoë¥¼ ì°¸ê³ í•˜ì—¬ ì•„ë˜ì— ì£¼ì–´ì§„ Task Descriptionì— ë”°ë¼ ë‹¨ê³„ì ìœ¼ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

## Task Description:
1. Step 1: ì‚¬ìš©ì ë©”ì‹œì§€ì— í•„ìˆ˜ ì—”í‹°í‹° "ë„ì‹œëª…(City Name)"ì´ ì—†ìœ¼ë©´ ìš”ì²­ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ì‘ë‹µ ë©”ì‹œì§€ì˜ ë§ˆì§€ë§‰ì— <|require-city|> í† í°ì„ ë¶™ì…ë‹ˆë‹¤.
    <example>ì •í™•í•˜ê²Œ ë„ì‹œì˜ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (ex. ì„œìš¸, ë² ì´ì§•)</example>
    <example>ì–´ëŠ ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ê°€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?</example>

2. Step 2: ì‚¬ìš©ì ë©”ì‹œì§€ì— "ë„ì‹œëª…(City Name)"ì´ ìˆìœ¼ë©´ ë„ì‹œëª…ë§Œ ì˜ì–´ë¡œ ê²°ê³¼ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ì‘ë‹µ ë©”ì‹œì§€ì˜ ë§ˆì§€ë§‰ì— <|require-weather|> í† í°ì„ ë¶™ì…ë‹ˆë‹¤.
    <example>ì„œìš¸ì…ë‹ˆë‹¤. -> Seoul</example>
    <example>í† ë¡ í†  -> Toronto</example>
    <example>í™ì½© -> Hongkong</example>

3. Step 3: Weather Infoì— ë‚ ì”¨ ì •ë³´ê°€ ìˆë‹¤ë©´ ì´ë¥¼ ì°¸ì¡°í•˜ì—¬ ì‚¬ìš©ìì˜ ë‚ ì”¨ì •ë³´ ë¬¸ì˜ì— ëŒ€í•œ ì‘ë‹µ ë©”ì‹œì§€ë¥¼ í•œê¸€ë¡œ ì‘ì„±í•©ë‹ˆë‹¤. ì‘ë‹µ ë©”ì‹œì§€ì˜ ë§ˆì§€ë§‰ì— <|end-weather|> í† í°ì„ ë¶™ì…ë‹ˆë‹¤.
    <example>í† ë¡ í† ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” ë§‘ê³  â˜€ï¸  ê¸°ì˜¨ì€ 25.1Â°C ì…ë‹ˆë‹¤.</example>
    <example>ë„ì¿„ëŠ” ì§€ê¸ˆ êµ¬ë¦„ì´ ë¼ì—ˆê³  ğŸŒ¥ï¸  ê¸°ì˜¨ì€ 31.8Â°C ì…ë‹ˆë‹¤.</example>

4. Step 4: <|end-weather|> ìƒíƒœì´ê³ , ì¶”ê°€ì ì¸ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´ í•´ë‹¹ ë©”ì‹œì§€ì— ëŒ€í•œ ì˜¬ë°”ë¥¸ ë‹µë³€ì„ ì‘ì„±í•©ë‹ˆë‹¤.

5. Step 5: ë³„ë‹¤ë¥¸ ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆëŠ”ì§€ ë¬¼ì–´ë³´ê³  ì—†ë‹¤ê³  í•œë‹¤ë©´, ê°ì‚¬í•©ë‹ˆë‹¤ë¼ëŠ” ë¬¸êµ¬ë¡œ ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.

## Weather Info:
"""

    def process_user_message(self, user_message):
        self.messages.append({"role": "user", "content": user_message})
        assistant_message = self.chat_completion()
        
        if '<|require-city|>' in assistant_message:
            assistant_message = assistant_message.replace('<|require-city|>', '').strip()
            self.messages.append({"role": "assistant", "content": assistant_message})

        elif '<|require-weather|>' in assistant_message:
            assistant_message = assistant_message.replace('<|require-weather|>', '').strip()
            weather_info = self._get_weather(assistant_message)
            if weather_info:
                self._update_weather_info(weather_info)
                self.messages.append({"role": "assistant", "content": assistant_message})
                assistant_message = self.chat_completion(temperature=0)
                if '<|end-weather|>' in assistant_message:
                    self.messages.append({"role": "assistant", "content": assistant_message})
                    pass
                else:
                    assistant_message = "âš ï¸ ë‚ ì”¨ API í†µì‹  ì´ìŠˆê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ë™ì¼í•œ ë‚´ìš©ì„ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
            else:
                assistant_message = "âš ï¸ ì…ë ¥í•˜ì‹  ì •ë³´ì˜ ë‚ ì”¨ ì¡°íšŒ ì„œë¹„ìŠ¤ëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                self.messages.append({"role": "assistant", "content": assistant_message})

        else:
            self.messages.append({"role": "assistant", "content": assistant_message})
        
        # make sure remove token
        return assistant_message.replace('<|end-weather|>', '').replace('<|require-weather|>', '')
            
    def _get_weather(self, city):
        api_url = f"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={self.weather_api_key}&units=metric&lang=kr"
        response = requests.get(api_url)
        if response.status_code == 200:
            data = response.json()
            description = data.get('weather', [{}])[0].get('description', '')
            temp = data.get('main', {}).get('temp', '')
            return {'description': description, 'temp': temp}
        return {}
    
    def _update_weather_info(self, weather_info):
        description = weather_info["description"]
        temperature = weather_info["temp"]
        updated_system = self.messages[0]["content"] + f'- description: {description}\n- temperature: {temperature}'
        self.messages[0] = {"role": "system", "content": updated_system}


class FaqAgent(Agent):
    def __init__(self, chroma_client, embedding_function):
        super().__init__()
        self.collection = chroma_client.get_collection(name="faq", embedding_function=embedding_function)
    
    @staticmethod
    def initialize_system_message():
        return """You are the helpful AI assistant to answer the given User message. You should reference the relevant FAQs below."""

    def search(self, query):
        results = self.collection.query(
            query_texts=[query],
            n_results=5,
        )
        results = results['documents'][0]
        documents = "\n\n<FAQ>\n"
        documents += "\n\n".join([f"{idx+1}. relevant document: {doc}" for idx,  doc in enumerate(results)])
        self.messages.append({"role": "system", "content": self.initialize_system_message() + documents})

    def process_user_message(self, user_message):
        if len(self.messages) == 0:
            self.search(user_message)

        self.messages.append({"role": "user", "content": user_message})
        assistant_message = self.chat_completion()
        self.messages.append({"role": "assistant", "content": assistant_message})

        return assistant_message


class CommunityAgent(Agent):
    def __init__(self, chroma_client, embedding_function):
        super().__init__()
        self.collection = chroma_client.get_collection(name="community", embedding_function=embedding_function)
        
    @staticmethod
    def initialize_system_message():
        return """You are the helpful AI assistant to answer the given User message. You should reference the relevant documents below. If the documents are not relevant to the User message, do not reference the documents.

<Retrieved Documents>
{}

Consideration: If the document is not relevant to the User message, do not reference the documents.
"""

    def search(self, query):
        results = self.collection.query(
            query_texts=[query],
            n_results=3,
        )
        results = results['documents'][0]
        documents = "\n\n".join([f"{idx+1}. relevant document: {doc}" for idx,  doc in enumerate(results)])
        self.messages.append({"role": "system", "content": self.initialize_system_message().format(documents)})

    def process_user_message(self, user_message):
        if len(self.messages) == 0:
            self.search(user_message)

        self.messages.append({"role": "user", "content": user_message})
        assistant_message = self.chat_completion()
        self.messages.append({"role": "assistant", "content": assistant_message})

        return assistant_message


class AccmAgent(Agent):
    def __init__(self, chroma_client, embedding_function):
        super().__init__()
        self.collection = chroma_client.get_collection(name="accommodation", embedding_function=embedding_function)

    @staticmethod
    def initialize_system_message():
        return """You are the helpful AI assistant to answer the given User message. You should reference the relevant documents below. The documents are the information about the accommodations. And you should summarize and provide the essential information to the customer about the retrieved accommodations. Please follow the below Accommodation Template.

<Accommodation Template>
1. '''Input ìˆ™ì†Œ ì´ë¦„ in the accommodatio document'''
  - ìœ„ì¹˜: '''Input ìœ„ì¹˜ì •ë³´ in the accommodation document'''
  - ìˆ™ì†Œì •ë³´: '''Input summarized text of ìˆ™ì†Œê°œìš” in the accommodation document
  - ì¶”ì²œ ì´ìœ : '''Input text to recommend the accommodation'''
  - ê¸°íƒ€ ì œê³µ ì„œë¹„ìŠ¤: '''Input few other ìˆ™ì†Œ ì œê³µ ì„œë¹„ìŠ¤ to get attraction in the accommodation document'''
2. ...


<Retrieved Documnets>
{}

Consideration: If ìœ„ì¹˜ of the accommodation is not relevant to the User message, do not reference the documents.
"""

    def search(self, query):
        results = self.collection.query(
            query_texts=[query],
            n_results=3,
        )
        results = results['documents'][0]
        documents = "\n\n".join([f"{idx+1}. relevant document: {doc}" for idx,  doc in enumerate(results)])
        self.messages.append({"role": "system", "content": self.initialize_system_message().format(documents)})

    def process_user_message(self, user_message):
        if len(self.messages) == 0:
            self.search(user_message)

        self.messages.append({"role": "user", "content": user_message})
        assistant_message = self.chat_completion(max_tokens=1024)
        self.messages.append({"role": "assistant", "content": assistant_message})

        return assistant_message 
